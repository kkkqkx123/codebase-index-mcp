# Environment Configuration
NODE_ENV = development
PORT = 3000

# Database Configuration
# Qdrant Configuration
QDRANT_HOST = localhost
QDRANT_PORT = 6333
QDRANT_COLLECTION = code-snippets

# NebulaGraph Configuration
NEBULA_HOST = localhost
NEBULA_PORT = 9669
NEBULA_USERNAME = root
NEBULA_PASSWORD = nebula
NEBULA_SPACE = codebase_index

# Embedding Configuration
EMBEDDING_PROVIDER = openai
OPENAI_API_KEY = your-openai-api-key-here
OPENAI_MODEL = text-embedding-ada-002

# Alternative embedding providers
OLLAMA_BASE_URL = http://localhost:11434
OLLAMA_MODEL = nomic-embed-text

# OpenAI with custom base URL support
OPENAI_BASE_URL = https://api.openai.com
# GEMINI_API_KEY = your-gemini-api-key-here
GEMINI_BASE_URL = https://generativelanguage.googleapis.com
GEMINI_MODEL = embedding-001

# MISTRAL_API_KEY = your-mistral-api-key-here
MISTRAL_BASE_URL = https://api.mistral.ai
MISTRAL_MODEL = mistral-embed

# SiliconFlow configuration (set your URL in .env file)
SILICONFLOW_API_KEY = your-siliconflow-api-key-here
SILICONFLOW_BASE_URL = https://api.siliconflow.cn/v1
SILICONFLOW_MODEL = BAAI/bge-m3

# Custom embedder configurations (set your URLs in .env file)
CUSTOM_CUSTOM1_API_KEY = your-custom1-api-key-here
CUSTOM_CUSTOM1_BASE_URL = 
CUSTOM_CUSTOM1_MODEL = your-custom1-model-here

CUSTOM_CUSTOM2_API_KEY = your-custom2-api-key-here
CUSTOM_CUSTOM2_BASE_URL = 
CUSTOM_CUSTOM2_MODEL = your-custom2-model-here

CUSTOM_CUSTOM3_API_KEY = your-custom3-api-key-here
CUSTOM_CUSTOM3_BASE_URL = 
CUSTOM_CUSTOM3_MODEL = your-custom3-model-here

# Logging Configuration
LOG_LEVEL = info
LOG_FORMAT = json

# Monitoring Configuration
ENABLE_METRICS = true
METRICS_PORT = 9090

# File Processing Configuration
MAX_FILE_SIZE = 10485760
SUPPORTED_EXTENSIONS = .ts,.js,.py,.java,.go,.rs,.cpp,.c,.h
INDEX_BATCH_SIZE = 100
CHUNK_SIZE = 1000
OVERLAP_SIZE = 200